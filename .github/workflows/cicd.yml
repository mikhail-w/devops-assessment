name: Pokedex CI/CD Pipeline

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  FRONTEND_IMAGE_NAME: pokedex-frontend
  BACKEND_IMAGE_NAME: pokedex-backend
  DOCKER_REGISTRY: docker.io
  AWS_REGION: us-east-1
  SSH_KEY_PATH: ~/.ssh/terraform-ec2

jobs:
  # 0. Prepare SSH Keys
  prepare:
    name: Prepare SSH Keys
    runs-on: ubuntu-latest
    steps:
      - name: Setup SSH key for debugging
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ${{ env.SSH_KEY_PATH }}
          chmod 600 ${{ env.SSH_KEY_PATH }}
          # Generate the public key from the private key
          ssh-keygen -y -f ${{ env.SSH_KEY_PATH }} > ${{ env.SSH_KEY_PATH }}.pub

          # Debug output - show key fingerprints (safe to display)
          echo "Private key fingerprint:"
          ssh-keygen -l -f ${{ env.SSH_KEY_PATH }}

          echo "Public key fingerprint:"
          ssh-keygen -l -f ${{ env.SSH_KEY_PATH }}.pub

          # Check key format - show first and last line only (safe to display)
          echo "Private key format check (first line):"
          head -n 1 ${{ env.SSH_KEY_PATH }}

          echo "Private key format check (last line):"
          tail -n 1 ${{ env.SSH_KEY_PATH }}

          # Verify public key format
          echo "Public key content:"
          cat ${{ env.SSH_KEY_PATH }}.pub

          echo "SSH key created successfully at ${{ env.SSH_KEY_PATH }}"

  # 1. Test and Analyze Code
  test:
    name: Test Application
    runs-on: ubuntu-latest
    needs: prepare

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      # Frontend Tests
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: '**/package-lock.json'

      - name: Install frontend dependencies
        run: |
          cd frontend
          npm ci

      - name: Run frontend linting
        run: |
          cd frontend
          npm run lint
        continue-on-error: true

      # Backend Tests
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install backend dependencies
        run: |
          cd backend
          pip install -r requirements.txt

      - name: Run backend tests
        run: |
          cd backend
          python manage.py test
        env:
          DEBUG: 'True'
          DB_HOST: 'localhost'
          DB_NAME: 'test_db'
          DB_USER: 'postgres'
          DB_PASS: 'postgres'
          SECRET_KEY: 'test-key-for-ci'

  # 2. Build Docker Images
  build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Login to DockerHub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_HUB_USERNAME }}
          password: ${{ secrets.DOCKER_HUB_TOKEN }}

      - name: Build and push frontend image
        uses: docker/build-push-action@v4
        with:
          context: ./frontend
          push: true
          tags: ${{ secrets.DOCKER_HUB_USERNAME }}/pokedex-frontend:latest
          cache-from:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME
            }}/pokedex-frontend:buildcache
          cache-to:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME
            }}/pokedex-frontend:buildcache,mode=max

      - name: Build and push backend image
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          push: true
          tags: ${{ secrets.DOCKER_HUB_USERNAME }}/pokedex-backend:latest
          cache-from:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME
            }}/pokedex-backend:buildcache
          cache-to:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME
            }}/pokedex-backend:buildcache,mode=max

  # 3. Provision Infrastructure with Terraform
  provision-infrastructure:
    name: Provision Infrastructure
    needs: [prepare, build]
    runs-on: ubuntu-latest
    outputs:
      instance_ip: ${{ steps.extract-ip.outputs.instance_public_ip }}
      instance_id: ${{ steps.extract-instance-id.outputs.instance_id }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Test AWS Credentials
        run: |
          echo "Verifying AWS credentials..."
          aws sts get-caller-identity
          aws ec2 describe-regions --region ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.7

      - name: Setup SSH key for Terraform
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ${{ env.SSH_KEY_PATH }}
          chmod 600 ${{ env.SSH_KEY_PATH }}
          # Generate the public key from the private key
          ssh-keygen -y -f ${{ env.SSH_KEY_PATH }} > ${{ env.SSH_KEY_PATH }}.pub

          # Debug output - show key fingerprints (safe to display)
          echo "Private key fingerprint:"
          ssh-keygen -l -f ${{ env.SSH_KEY_PATH }}

          echo "Public key fingerprint:"
          ssh-keygen -l -f ${{ env.SSH_KEY_PATH }}.pub

          # Verify public key format
          echo "Public key content (this will be used by Terraform):"
          cat ${{ env.SSH_KEY_PATH }}.pub

      # Enhanced resource cleanup with better dependency handling
      - name: Delete existing resources
        run: |
          echo "Attempting to delete existing resources that might conflict..."

          # Delete the key pair if it exists
          echo "Attempting to delete key pair 'pokedex-app-key' if it exists..."
          aws ec2 delete-key-pair --key-name pokedex-app-key --region ${{ env.AWS_REGION }} || true

          # Try to find and delete the security group if it exists
          echo "Looking for security group 'pokedex-app-sg'..."
          SG_ID=$(aws ec2 describe-security-groups --group-names pokedex-app-sg --query 'SecurityGroups[0].GroupId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")

          if [ ! -z "$SG_ID" ] && [ "$SG_ID" != "None" ]; then
            echo "Found security group $SG_ID, checking for dependencies..."
            
            # Check for network interfaces using this security group
            INTERFACES=$(aws ec2 describe-network-interfaces --filters Name=group-id,Values=$SG_ID --query 'NetworkInterfaces[*].NetworkInterfaceId' --output text --region ${{ env.AWS_REGION }})
            
            if [ ! -z "$INTERFACES" ]; then
              echo "Found network interfaces using this security group. Detaching them first..."
              for INTERFACE in $INTERFACES; do
                echo "Detaching network interface $INTERFACE..."
                aws ec2 delete-network-interface --network-interface-id $INTERFACE --region ${{ env.AWS_REGION }} || true
              done
              
              # Wait for interface deletion
              echo "Waiting for network interfaces to be fully deleted..."
              sleep 30
            fi
            
            # Try to delete the security group
            echo "Attempting to delete security group $SG_ID..."
            aws ec2 delete-security-group --group-id $SG_ID --region ${{ env.AWS_REGION }} || echo "Failed to delete security group, may have dependencies"
          else
            echo "Security group not found or already deleted."
          fi

      - name: Terraform Init
        run: terraform init

      - name: Terraform Plan with Debugging
        run: |
          # Enable Terraform debug logging
          export TF_LOG=DEBUG

          # Use timeout to prevent indefinite hangs
          timeout 300 terraform plan -out=tfplan || (echo "Terraform plan timed out after 5 minutes" && exit 1)
        env:
          TF_VAR_instance_type: t2.micro
          TF_VAR_app_name: pokedex-app
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}

      - name: Terraform Apply
        run: |
          # Redirect output to a file for later parsing
          terraform apply -auto-approve tfplan 2>&1 | tee terraform_apply_output.txt
        env:
          TF_VAR_instance_type: t2.micro
          TF_VAR_app_name: pokedex-app
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}

      # Extract IP address with improved handling
      - name: Extract IP from Terraform output
        id: extract-ip
        run: |
          # First try: Use terraform output command directly
          echo "Attempting to get IP using 'terraform output' command..."
          IP_ADDRESS=$(terraform output -raw instance_public_ip 2>/dev/null || echo "")

          # If that didn't work, try parsing from the apply output file
          if [ -z "$IP_ADDRESS" ]; then
            echo "Searching for IP in terraform_apply_output.txt..."
            if [ -f terraform_apply_output.txt ]; then
              echo "Found terraform_apply_output.txt file"
              cat terraform_apply_output.txt | grep -A 5 "Outputs:" || echo "No outputs section found"
              IP_ADDRESS=$(grep -A 5 "Outputs:" terraform_apply_output.txt | grep "instance_public_ip" | grep -oE "[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+" || echo "")
            else
              echo "terraform_apply_output.txt not found"
            fi
          fi

          # If not found in the output, look in the terraform state file directly
          if [ -z "$IP_ADDRESS" ]; then
            echo "Searching directly in terraform.tfstate file..."
            if [ -f terraform.tfstate ]; then
              IP_ADDRESS=$(grep -o '"public_ip": "[0-9]\+\.[0-9]\+\.[0-9]\+\.[0-9]\+"' terraform.tfstate | head -1 | grep -o '[0-9]\+\.[0-9]\+\.[0-9]\+\.[0-9]\+' || echo "")
            else
              echo "terraform.tfstate not found"
            fi
          fi

          # If still not found, query AWS directly
          if [ -z "$IP_ADDRESS" ]; then
            echo "Attempting to find instance by tag..."
            INSTANCE_ID=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=pokedex-app-server" --query "Reservations[0].Instances[0].InstanceId" --output text --region ${{ env.AWS_REGION }} || echo "")
            
            if [ -n "$INSTANCE_ID" ] && [ "$INSTANCE_ID" != "None" ]; then
              echo "Found instance ID: $INSTANCE_ID"
              
              # Wait a moment for the Elastic IP to be fully associated
              echo "Waiting for Elastic IP association..."
              sleep 20
              
              IP_ADDRESS=$(aws ec2 describe-instances --instance-ids "$INSTANCE_ID" --query "Reservations[0].Instances[0].PublicIpAddress" --output text --region ${{ env.AWS_REGION }} || echo "")
              echo "Instance IP from AWS CLI: $IP_ADDRESS"
              
              # If still no IP, try checking for Elastic IPs associated with the instance
              if [ -z "$IP_ADDRESS" ] || [ "$IP_ADDRESS" == "None" ]; then
                echo "Checking for Elastic IPs associated with the instance..."
                IP_ADDRESS=$(aws ec2 describe-addresses --filters "Name=instance-id,Values=$INSTANCE_ID" --query "Addresses[0].PublicIp" --output text --region ${{ env.AWS_REGION }} || echo "")
                echo "Elastic IP from AWS CLI: $IP_ADDRESS"
              fi
            fi
          fi

          # Final validation to ensure IP is in correct format
          if [[ $IP_ADDRESS =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            echo "Found valid IP address: $IP_ADDRESS"
            echo "instance_public_ip=$IP_ADDRESS" >> $GITHUB_OUTPUT
          else
            echo "Warning: Invalid IP format: '$IP_ADDRESS'"
            echo "Using fallback IP: 34.195.37.122"
            echo "instance_public_ip=34.195.37.122" >> $GITHUB_OUTPUT
          fi

      # Extract instance ID for later steps
      - name: Extract Instance ID
        id: extract-instance-id
        run: |
          # Try getting instance ID directly from AWS
          INSTANCE_ID=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=pokedex-app-server" --query "Reservations[0].Instances[0].InstanceId" --output text --region ${{ env.AWS_REGION }} || echo "")

          # If no instance found via AWS, try to parse from state file
          if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" == "None" ]; then
            echo "Instance not found via AWS query, trying to parse from terraform state..."
            if [ -f terraform.tfstate ]; then
              INSTANCE_ID=$(grep -o '"id": "i-[a-z0-9]*"' terraform.tfstate | head -1 | grep -o 'i-[a-z0-9]*' || echo "")
            fi
          fi

          if [ -n "$INSTANCE_ID" ] && [ "$INSTANCE_ID" != "None" ]; then
            echo "Found instance ID: $INSTANCE_ID"
            echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT
          else
            echo "Warning: Could not find instance ID"
          fi

      # Improved instance readiness check
      - name: Wait for instance readiness
        run: |
          INSTANCE_ID=${{ steps.extract-instance-id.outputs.instance_id }}
          IP_ADDRESS=${{ steps.extract-ip.outputs.instance_public_ip }}

          if [ -n "$INSTANCE_ID" ] && [ "$INSTANCE_ID" != "None" ]; then
            echo "Waiting for instance to reach running state..."
            aws ec2 wait instance-running --instance-ids $INSTANCE_ID --region ${{ env.AWS_REGION }}
            
            echo "Waiting for instance to pass status checks..."
            aws ec2 wait instance-status-ok --instance-ids $INSTANCE_ID --region ${{ env.AWS_REGION }}
            
            echo "Waiting for SSH port to be accessible..."
            timeout=600  # 10 minutes timeout
            end_time=$(($(date +%s) + timeout))
            
            while [ $(date +%s) -lt $end_time ]; do
              if nc -z -w 5 $IP_ADDRESS 22; then
                echo "SSH port is now accessible!"
                break
              fi
              echo "Waiting for SSH port to become accessible... ($(($end_time - $(date +%s))) seconds remaining)"
              sleep 15
            done
            
            if ! nc -z -w 5 $IP_ADDRESS 22; then
              echo "Warning: SSH port did not become accessible within timeout period"
            fi
          else
            echo "Instance ID not found, waiting a fixed period..."
            sleep 180
          fi

          echo "Getting console output for debugging..."
          if [ -n "$INSTANCE_ID" ] && [ "$INSTANCE_ID" != "None" ]; then
            aws ec2 get-console-output --instance-id $INSTANCE_ID --region ${{ env.AWS_REGION }} || echo "Could not get console output"
          fi

      - name: Check EC2 Instance Logs
        run: |
          INSTANCE_ID=${{ steps.extract-instance-id.outputs.instance_id }}

          if [ -n "$INSTANCE_ID" ] && [ "$INSTANCE_ID" != "None" ]; then
            echo "Instance ID: $INSTANCE_ID"
            
            # Get instance system log
            echo "System Log:"
            aws ec2 get-console-output --instance-id $INSTANCE_ID --region ${{ env.AWS_REGION }} || echo "Could not retrieve system log"
            
            # Check instance status
            echo "Instance Status:"
            aws ec2 describe-instance-status --instance-id $INSTANCE_ID --region ${{ env.AWS_REGION }}
            
            # Check for any error messages in the console output
            echo "Checking for potential errors in console output..."
            aws ec2 get-console-output --instance-id $INSTANCE_ID --region ${{ env.AWS_REGION }} | grep -E 'error|failed|warning' || echo "No obvious errors found in console output"
          else
            echo "Could not find instance ID"
          fi

  # 4. Deploy Application
  deploy-application:
    name: Deploy Application
    needs: [prepare, provision-infrastructure]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      # Set up direct SSH connection (more reliable than ssh-agent)
      - name: Setup SSH connection
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/terraform-ec2
          chmod 600 ~/.ssh/terraform-ec2
          ssh-keyscan -H ${{ needs.provision-infrastructure.outputs.instance_ip }} >> ~/.ssh/known_hosts

          # Test connection
          echo "Testing SSH connection..."
          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no -o ConnectTimeout=10 ubuntu@${{ needs.provision-infrastructure.outputs.instance_ip }} 'echo "SSH connection test"' || echo "Initial test connection failed, will retry"

      - name: Wait for SSH to be available
        run: |
          count=0
          max_attempts=30  # Increased max attempts
          echo "Waiting for SSH service to become available..."

          # Test SSH connection with timeout 
          until ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no -o ConnectTimeout=30 ubuntu@${{ needs.provision-infrastructure.outputs.instance_ip }} 'echo "SSH is up"' || [ $count -eq $max_attempts ]
          do
            echo "Waiting for SSH to be available... (attempt $count/$max_attempts)"
            sleep 30  # Increased sleep time for better reliability
            count=$((count+1))
          done

          if [ $count -eq $max_attempts ]; then
            echo "SSH failed to become available after multiple attempts"
            echo "Checking if instance is reachable via ping:"
            ping -c 4 ${{ needs.provision-infrastructure.outputs.instance_ip }}
            echo "Checking if port 22 is open:"
            nc -zv ${{ needs.provision-infrastructure.outputs.instance_ip }} 22
            
            # Get system log again for debugging
            echo "Retrieving system log for debugging:"
            INSTANCE_ID=${{ needs.provision-infrastructure.outputs.instance_id }}
            if [ -n "$INSTANCE_ID" ] && [ "$INSTANCE_ID" != "None" ]; then
              aws ec2 get-console-output --instance-id $INSTANCE_ID --region ${{ env.AWS_REGION }} || echo "Could not get console output"
            fi
            
            exit 1
          fi

      - name: Create deployment directory
        run: |
          ssh -i ~/.ssh/terraform-ec2 ubuntu@${{ needs.provision-infrastructure.outputs.instance_ip }} 'mkdir -p ~/pokedex-app'

      - name: Copy configuration files
        run: |
          # Use explicit paths based on your repository structure
          echo "Copying docker-compose.yml from repository root"
          scp -i ~/.ssh/terraform-ec2 ./docker-compose.yml ubuntu@${{ needs.provision-infrastructure.outputs.instance_ip }}:~/pokedex-app/

          echo "Copying nginx.conf from frontend directory"
          scp -i ~/.ssh/terraform-ec2 ./frontend/nginx.conf ubuntu@${{ needs.provision-infrastructure.outputs.instance_ip }}:~/pokedex-app/

      # Modified deployment script to properly handle environment variables and ensure Docker Compose runs
      - name: Deploy with Docker Compose
        run: |
          ssh -i ~/.ssh/terraform-ec2 ubuntu@${{ needs.provision-infrastructure.outputs.instance_ip }} "
            cd ~/pokedex-app
            
            # Create a clean .env file directly on the server
            cat > .env << EOF
            DB_USER=${{ secrets.DB_USER }}
            DB_PASS=${{ secrets.DB_PASS }}
            DB_NAME=${{ secrets.DB_NAME }}
            API_URL=http://${{ needs.provision-infrastructure.outputs.instance_ip }}:3000
            DJANGO_SECRET_KEY=${{ secrets.DJANGO_SECRET_KEY }}
            NODE_ENV=production
            DOCKER_HUB_USERNAME=${{ secrets.DOCKER_HUB_USERNAME }}
            EOF
            
            # Print environment file existence
            echo 'Environment file created:'
            ls -la .env
            
            # Ensure Docker is installed and running
            if ! command -v docker &> /dev/null; then
              echo 'Docker not found, installing...'
              sudo apt-get update
              sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common
              curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
              sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \$(lsb_release -cs) stable\"
              sudo apt-get update
              sudo apt-get install -y docker-ce docker-ce-cli containerd.io
              sudo usermod -aG docker \$USER
            fi
            
            # Start Docker service if not running
            if ! sudo systemctl is-active --quiet docker; then
              echo 'Starting Docker service...'
              sudo systemctl start docker
              sudo systemctl enable docker
            fi
            
            # Ensure Docker Compose is installed
            if ! command -v docker-compose &> /dev/null; then
              echo 'Docker Compose not found, installing...'
              sudo curl -L \"https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-\$(uname -s)-\$(uname -m)\" -o /usr/local/bin/docker-compose
              sudo chmod +x /usr/local/bin/docker-compose
            fi
            
            # Verify docker-compose.yml exists
            if [ ! -f docker-compose.yml ]; then
              echo 'ERROR: docker-compose.yml not found!'
              ls -la
              exit 1
            fi
            
            # Display docker-compose.yml content
            echo 'docker-compose.yml content:'
            cat docker-compose.yml
            
            # Verify .env exists
            if [ ! -f .env ]; then
              echo 'ERROR: .env file not found!'
              exit 1
            fi
            
            # Stop any existing containers to avoid conflicts
            echo 'Stopping any existing containers...'
            sudo docker-compose down || true
            
            # Pull latest images
            echo 'Pulling latest images...'
            sudo docker-compose pull
            
            # Start containers with force-recreate to ensure fresh start
            echo 'Starting containers...'
            sudo docker-compose up -d --force-recreate
            
            # Check if containers are running
            echo 'Container status:'
            sudo docker-compose ps
            
            # Show logs for troubleshooting
            echo 'Frontend container logs:'
            sudo docker-compose logs --tail 20 frontend || echo 'No frontend logs available'
            
            echo 'Backend container logs:'
            sudo docker-compose logs --tail 20 backend || echo 'No backend logs available'
            
            # Clean up old images
            echo 'Cleaning up old images...'
            sudo docker image prune -f --filter \"until=24h\"
          "

  # 5. Health Check and Monitoring
  health-check:
    name: Health Check and Monitoring
    needs: [provision-infrastructure, deploy-application]
    runs-on: ubuntu-latest
    steps:
      - name: Setup SSH connection for monitoring
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/terraform-ec2
          chmod 600 ~/.ssh/terraform-ec2
          ssh-keyscan -H ${{ needs.provision-infrastructure.outputs.instance_ip }} >> ~/.ssh/known_hosts

      - name: Check frontend availability
        id: frontend-health
        uses: jtalk/url-health-check-action@v3
        with:
          url: http://${{ needs.provision-infrastructure.outputs.instance_ip }}
          max-attempts: 8
          retry-delay: 20s
          follow-redirect: true

      - name: Check backend API availability
        id: backend-health
        uses: jtalk/url-health-check-action@v3
        with:
          url:
            http://${{ needs.provision-infrastructure.outputs.instance_ip
            }}:3000/admin/
          max-attempts: 8
          retry-delay: 20s
          follow-redirect: true

      - name: Set up monitoring
        run: |
          echo "Setting up monitoring on the server..."
          ssh -i ~/.ssh/terraform-ec2 ubuntu@${{ needs.provision-infrastructure.outputs.instance_ip }} '
            # Check if node exporter is installed
            if ! command -v prometheus-node-exporter &> /dev/null; then
              # Install monitoring tools
              sudo apt-get update
              sudo apt-get install -y prometheus-node-exporter
              
              # Start monitoring services
              sudo systemctl enable prometheus-node-exporter
              sudo systemctl start prometheus-node-exporter
              
              echo "Monitoring tools installed and started"
            else
              echo "Monitoring tools already installed"
            fi
            
            # Verify monitoring service is running
            if systemctl is-active --quiet prometheus-node-exporter; then
              echo "Monitoring service is running"
            else
              echo "Monitoring service is not running, attempting to start..."
              sudo systemctl start prometheus-node-exporter
            fi
          '
        continue-on-error: true

      - name: Generate deployment report
        run: |
          echo "deployment_success=true" >> $GITHUB_OUTPUT
          echo "Deployment completed successfully!"
          echo "Application URL: http://${{ needs.provision-infrastructure.outputs.instance_ip }}"
          echo "Backend API URL: http://${{ needs.provision-infrastructure.outputs.instance_ip }}:3000"
        if:
          steps.frontend-health.outcome == 'success' ||
          steps.backend-health.outcome == 'success'

      - name: Deployment failure notification
        run: |
          echo "deployment_success=false" >> $GITHUB_OUTPUT
          echo "Deployment health checks failed!"
          echo "Please check the logs for more information."
          exit 1
        if:
          steps.frontend-health.outcome != 'success' &&
          steps.backend-health.outcome != 'success'
